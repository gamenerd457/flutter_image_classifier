{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cat_dog_classifier.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "7FiDPCjDun26"
      },
      "source": [
        "#importing the required packages\n",
        "import numpy as np\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.layers import Dense,Flatten,Dropout\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0T2KfWEYuyv1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "72e7af9e-929e-48bd-c16e-c3d30faba708"
      },
      "source": [
        "#downloading the cat and dogs datasets putting them into directories\n",
        "_URL = 'https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip'\n",
        "path_to_zip = tf.keras.utils.get_file('cats_and_dogs.zip', origin=_URL, extract=True)\n",
        "PATH = os.path.join(os.path.dirname(path_to_zip), 'cats_and_dogs_filtered')\n",
        "\n",
        "train_dir = os.path.join(PATH, 'train')\n",
        "validation_dir = os.path.join(PATH, 'validation')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip\n",
            "68608000/68606236 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pKHc8S6IvVWl"
      },
      "source": [
        "batch_size=32#we are taking 32 images in one batch\n",
        "image_size=(150,150)# we are resizing the images \n",
        "train_data_gen=ImageDataGenerator(\n",
        "    width_shift_range=0.10,zoom_range=0.10,height_shift_range=0.10,fill_mode=\"nearest\",\n",
        "    rescale=1/255\n",
        ")#we are using ImageDatagenerators to augment the data\n",
        "\n",
        "\n",
        "val_data_gen=ImageDataGenerator(rescale=1/255)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2jOVcaDdvmHs",
        "outputId": "ad772ea7-7e59-4179-e07a-210fb3d167c9"
      },
      "source": [
        "train_data=train_data_gen.flow_from_directory(train_dir,batch_size=batch_size,target_size=image_size,class_mode=\"categorical\")#here we are creating the train and val data\n",
        "val_data=val_data_gen.flow_from_directory(validation_dir,batch_size=batch_size,target_size=image_size,class_mode=\"categorical\")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 2000 images belonging to 2 classes.\n",
            "Found 1000 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4tZXoWblxKkd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d9d2f3c-a3ec-4457-9148-3250ce163a9f"
      },
      "source": [
        "conv_base=VGG16(weights=\"imagenet\",include_top=False,input_shape=(150,150,3))#we are going to use Vgg16 and fine tune it\n",
        "conv_base.trainable=False"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58892288/58889256 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "snY1UBjsyDq7",
        "outputId": "9e7e2728-a53a-46c7-b22e-1b8fbe00661c"
      },
      "source": [
        "model=Sequential()\n",
        "model.add(conv_base)\n",
        "model.add(Flatten())#we are flattening the output from VGG16\n",
        "model.add(Dense(64,activation=\"relu\"))#we are creating a dense layer with 64,32 neurons\n",
        "model.add(Dense(32,activation=\"relu\"))\n",
        "model.add(Dense(2,activation=\"softmax\"))# here we are taking two output neurons and hence the softmax activation to get the confidence score of both cat and dogs,\n",
        "                                        #if we use binary classification we wil  get an error regarding output shapes   when deploying to flutter .\n",
        "model.summary()\n",
        "model.compile(loss=\"categorical_crossentropy\",optimizer=\"adam\",metrics=[\"acc\"])#compiling the model with loss as categorical crossentropy and optimizer as adam\n",
        "es=EarlyStopping(monitor=\"val_loss\")#using early stopping as callback to stop the model training if it starts to overfit"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "vgg16 (Functional)           (None, 4, 4, 512)         14714688  \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 8192)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 64)                524352    \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 32)                2080      \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 2)                 66        \n",
            "=================================================================\n",
            "Total params: 15,241,186\n",
            "Trainable params: 526,498\n",
            "Non-trainable params: 14,714,688\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v8Qd8-RnyxNq",
        "outputId": "ab87f669-6dd6-40e0-cc1e-a86e4514ce25"
      },
      "source": [
        "history=model.fit(train_data,steps_per_epoch=2000//batch_size,epochs=30,validation_data=val_data,validation_steps=1000//batch_size,callbacks=[es])#training the model"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "62/62 [==============================] - 60s 411ms/step - loss: 0.4892 - acc: 0.7467 - val_loss: 0.3228 - val_acc: 0.8558\n",
            "Epoch 2/30\n",
            "62/62 [==============================] - 22s 360ms/step - loss: 0.2649 - acc: 0.8880 - val_loss: 0.2831 - val_acc: 0.8911\n",
            "Epoch 3/30\n",
            "62/62 [==============================] - 22s 359ms/step - loss: 0.2106 - acc: 0.8980 - val_loss: 0.2621 - val_acc: 0.8881\n",
            "Epoch 4/30\n",
            "62/62 [==============================] - 22s 359ms/step - loss: 0.1807 - acc: 0.9308 - val_loss: 0.4509 - val_acc: 0.8367\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QSkspduS0XFC",
        "outputId": "d5940ecd-c8f0-49ca-cc9b-188ceec3cb90"
      },
      "source": [
        "conv_base.trainable = True#unfreezing the layers inorder to finetune it\n",
        "len(conv_base.layers)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "19"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lC-01a0W0p1y"
      },
      "source": [
        "for layer in conv_base.layers[:17]:#fintuning the model by unfreezing the last two layers\n",
        "  layer.trainable =  False"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_wnGC0Fc02ji"
      },
      "source": [
        "model.compile(loss=\"binary_crossentropy\",optimizer=\"adam\",metrics=[\"acc\"])#compiling the model again"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "3wPz5XRrmC9N",
        "outputId": "27274898-c7d1-45ac-e2e0-89a410b9e38e"
      },
      "source": [
        "train_dir"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/root/.keras/datasets/cats_and_dogs_filtered/train'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G2z7Ekjx05eq",
        "outputId": "c9d3ed59-64c3-42e8-c777-cd84c7f281f5"
      },
      "source": [
        "new_model=model.fit(train_data,epochs=30,validation_data=val_data,callbacks=[es],steps_per_epoch=2000//batch_size,validation_steps=1000//batch_size)#training the finetuned model"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "62/62 [==============================] - 22s 360ms/step - loss: 0.1725 - acc: 0.9350 - val_loss: 0.2930 - val_acc: 0.8851\n",
            "Epoch 2/30\n",
            "62/62 [==============================] - 22s 358ms/step - loss: 0.1345 - acc: 0.9497 - val_loss: 0.3147 - val_acc: 0.8851\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dk0JaZiv1JuK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1fcaec5-7040-47a3-d834-530eb4b71943"
      },
      "source": [
        "from tensorflow.keras.preprocessing import image\n",
        "import numpy as np\n",
        "test1=image.load_img('/content/The_Science-Backed_Benefits_of_Being_a_Dog_Owner.jpg',target_size=(150,150,3))\n",
        "test1=image.img_to_array(test1)\n",
        "test1=np.expand_dims(test1,axis=0)\n",
        "model.predict(test1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FsSTyiHzojSG",
        "outputId": "07714907-79fa-4bc8-8be1-4f010b4d7091"
      },
      "source": [
        "train_data.class_indices"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'cats': 0, 'dogs': 1}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tpJGcjAwouhG"
      },
      "source": [
        "import tensorflow as tf\n",
        "keras_file = \"cat_dog2.h5\"\n",
        "tf.keras.models.save_model(model , keras_file) #saving the keras model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gwGAs_kupkhd"
      },
      "source": [
        "test_model=tf.keras.models.load_model(\"cat_dog2.h5\")#loading the saved model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jCN5D089WHZZ",
        "outputId": "ddbf6492-31de-4452-f253-426c62a6bd71"
      },
      "source": [
        "converter = tf.lite.TFLiteConverter.from_keras_model(test_model)#converting the  saved model to tflite format\n",
        "tflite_model = converter.convert()\n",
        "open(\"cat_dog2.tflite\", \"wb\").write(tflite_model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmp7f2bhq5k/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmp7f2bhq5k/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "60975416"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dxpYqGA7WHC0"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6aDsU6Xwsx5E"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}